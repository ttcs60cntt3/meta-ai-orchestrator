//! Meta-AI Orchestrator main entry point

use meta_ai_common::{Config, telemetry};
use anyhow::Result;
use tracing::info;

#[tokio::main]
async fn main() -> Result<()> {
    // Load configuration
    let config = Config::load()
        .map_err(|e| anyhow::anyhow!("Failed to load config: {}", e))?;
    
    // Validate configuration
    if let Err(errors) = config.validate() {
        for error in errors {
            eprintln!("Config error: {}", error);
        }
        std::process::exit(1);
    }
    
    // Initialize telemetry
    telemetry::init_telemetry(&config.observability)?;
    
    info!("Starting Meta-AI Orchestrator v{}", env!("CARGO_PKG_VERSION"));
    info!("Configuration loaded successfully");
    
    // TODO: Initialize and start orchestrator
    println!("ðŸ¤– Meta-AI Orchestrator is starting...");
    println!("âœ… Configuration validated");
    println!("ðŸ“Š Telemetry initialized");
    println!("ðŸš€ Ready to process tasks!");
    
    // Keep running
    tokio::signal::ctrl_c().await?;
    
    info!("Shutting down Meta-AI Orchestrator");
    telemetry::shutdown_telemetry();
    
    Ok(())
}